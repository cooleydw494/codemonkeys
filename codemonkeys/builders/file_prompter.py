import os

from codemonkeys.config.imports.env import Env
from codemonkeys.defs import nl, nl2, _or, content_sep
from codemonkeys.utils.file_ops import get_file_contents
from codemonkeys.utils.gpt.gpt_client import GPTClient
from codemonkeys.utils.monk.theme_functions import print_t, verbose_logs_enabled

env = Env.get()


class FilePrompter:
    """Creates and configures a file prompter instance for generating _model outputs
    based on the given file content and the provided prompts.
    """

    _model = ''
    _temp = ''
    _max_tokens = None
    _gpt_client: GPTClient | None = None
    _file_path = None
    _file_name = None
    _main_prompt = ''
    _context = ''
    _output_example_prompt = ''
    _ultimatum_prompt = ''
    _skip_existing_output_files = False
    _output_remove_strings = []

    def file_path(self, file_path: str) -> 'FilePrompter':
        """Sets the file path and the file name to be used in the prompts.

        :param str file_path: The file path to set
        :return: FilePrompter: returns the updated instance
        """
        self._file_path = file_path
        self._file_name = os.path.basename(file_path)
        return self

    def context(self, context: str) -> 'FilePrompter':
        """Sets the _context to be used in the prompts.

        :param str context: The _context string to set
        :return: FilePrompter: returns the updated instance
        """
        self._context = context
        return self

    def main_prompt(self, main_prompt: str) -> 'FilePrompter':
        """Sets the main _prompt to be used in the prompts.

        :param str main_prompt: The main _prompt string to set
        :return: FilePrompter: returns the updated instance
        """
        self._main_prompt = main_prompt
        return self

    def ultimatum_prompt(self, ultimatum_prompt: str) -> 'FilePrompter':
        """Sets the ultimatum _prompt to be used in the prompts.

        :param str ultimatum_prompt: The ultimatum _prompt string to set
        :return: FilePrompter: returns the updated instance
        """
        self._ultimatum_prompt = ultimatum_prompt
        return self

    def output_example_prompt(self, output_example_prompt: str) -> 'FilePrompter':
        """Sets the output example _prompt to be used in the prompts.

        :param str output_example_prompt: The output example _prompt string to set
        :return: FilePrompter: returns the updated instance
        """
        self._output_example_prompt = output_example_prompt
        return self

    def model(self, model: str, temp: float, max_tokens: int) -> 'FilePrompter':
        """Sets the GPT _model, temperature, and max tokens to use for generating outputs.

        :param str model: The GPT _model to set
        :param float temp: The temperature to set
        :param int max_tokens: The maximum tokens to generate
        :return: FilePrompter: returns the updated instance
        """
        self._model = model
        self._temp = temp
        self._max_tokens = max_tokens
        self._gpt_client = GPTClient(model, temp, max_tokens)
        return self

    def output_remove_strings(self, output_remove_strings: str) -> 'FilePrompter':
        """Sets the output remove strings to automatically remove them from the generated output.

        :param str output_remove_strings: The comma-separated remove strings to set
        :return: FilePrompter: returns the updated instance
        """
        self._output_remove_strings = output_remove_strings.split(',')
        return self

    def get_output(self) -> str | None:
        """Gets the generated output from the GPT _model using the configured prompts.

        :return: str: The output generated by the _model
        """
        full_prompt, stubbed_prompt = self._get_full_prompt()
        if verbose_logs_enabled():
            print_t(f'Prompt: {full_prompt}', 'quiet')
        else:
            print_t(f"Prompt: {stubbed_prompt}", 'quiet')

        print_t("Generating output...", 'loading')
        output = self._gpt_client.generate(full_prompt)

        if output is None:
            return None

        if self._output_remove_strings is not None:
            for remove_str in self._output_remove_strings:
                output = output.replace(remove_str, '')

        print_t("Output returned.", 'info')
        print_t(f"{output}", 'quiet')
        return output

    def _get_full_prompt(self) -> (str, str):
        """Creates the full _prompt using the configured input options.

        :return: tuple of (str, str): Tuple of strings (full_prompt, stubbed_prompt)
        """
        main_prompt = _or(self._main_prompt)
        ultimatum = _or(self._ultimatum_prompt)
        output_example = _or(self._output_example_prompt)
        file_contents = get_file_contents(self._file_path)

        full_prompt = f"{main_prompt}{nl}{self._context}{nl}{self._file_name}:{nl}" \
                      f"{content_sep}{nl}{file_contents}{content_sep}{nl}{ultimatum}{nl}{output_example}"

        stubbed_prompt = f"{main_prompt}{nl2}<_context>{nl2}{self._file_name}:{nl}" \
                         f"{content_sep}<file contents>{content_sep}{nl2}<ultimatum>{nl2}<output example>"

        return full_prompt, stubbed_prompt
